# Multi-LLM Orchestrator ‚Äî Capabilities Reference

**Version:** 2026.02 | **Updated:** 2026-02-24 | **Latest:** Architecture Advisor for LLM-powered architecture decisions

This document provides a comprehensive overview of all capabilities, features, and advanced functionality available in the multi-llm-orchestrator.

---

## Core Capabilities

### 1. Multi-Provider Model Routing

The orchestrator automatically routes tasks to the optimal AI model based on task type, cost, performance metrics, and availability.

**Supported Providers:**
- **OpenAI** ‚Äî GPT-4o, GPT-4o-mini
- **Google** ‚Äî Gemini 2.5 Pro, Gemini 2.5 Flash
- **Anthropic** ‚Äî Claude 3.5 Opus, Claude 3.5 Sonnet, Claude 3.5 Haiku
- **Kimi (Moonshot)** ‚Äî K2.5 (moonshot-v1, with variants: 8K, 32K, 128K context)
- **DeepSeek** ‚Äî DeepSeek Chat (V3), DeepSeek Reasoner (R1)

**Task Types:** 7 core task types with optimized routing:
- `code_generation` ‚Äî Generate code with fallback chains
- `code_review` ‚Äî Cross-provider peer review
- `complex_reasoning` ‚Äî Multi-step analytical tasks
- `creative_writing` ‚Äî Long-form content generation
- `data_extraction` ‚Äî Structured information retrieval
- `summarization` ‚Äî Text condensing and abstraction
- `evaluation` ‚Äî Quality scoring and assessment

---

### 2. Intelligent Cost Optimization

#### Automatic Model Selection by Cost

Models are pre-ranked by cost-effectiveness for each task type. The orchestrator uses:
- **Cost Table:** Per-model pricing (per 1M tokens: input/output)
- **Adaptive EMA:** Tracks actual observed costs across runs
- **Fallback Chains:** Cross-provider fallbacks when primary model fails

**Cost Reference (per 1M tokens):**

| Model | Input | Output | Provider | Tier |
|-------|-------|--------|----------|------|
| DeepSeek Chat | $0.27 | $1.10 | DeepSeek | Ultra-cheap |
| Kimi K2.5 | $0.14 | $0.56 | Kimi | Ultra-cheap |
| Gemini Flash | $0.15 | $0.60 | Google | Ultra-cheap |
| GPT-4o-mini | $0.15 | $0.60 | OpenAI | Ultra-cheap |
| Claude Haiku | $0.80 | $4.00 | Anthropic | Budget |
| DeepSeek Reasoner | $0.55 | $2.19 | DeepSeek | Standard |
| Gemini 2.5 Pro | $1.25 | $10.00 | Google | Standard |
| GPT-4o | $2.50 | $10.00 | OpenAI | Standard |
| Claude Sonnet | $3.00 | $15.00 | Anthropic | Premium |
| Claude Opus | $15.00 | $75.00 | Anthropic | Premium |

#### Budget Partitioning

Soft allocation of budget across execution phases:

| Phase | % of Budget | Example ($8 total) |
|-------|------------|-------------------|
| Decomposition | 5% | $0.40 |
| Generation | 45% | $3.60 |
| Cross-review | 25% | $2.00 |
| Evaluation | 15% | $1.20 |
| Reserve | 10% | $0.80 |

---

### 3. Quality Assurance & Validation

#### Deterministic Validators

Hard validators that gate task completion (score = 0.0 on failure):

| Validator | Purpose | Requirement |
|-----------|---------|-------------|
| `python_syntax` | Compile Python code | Built-in; always available |
| `pytest` | Run unit tests | Optional; skipped if pytest not in PATH |
| `ruff` | Python linting | Optional; skipped if ruff not installed |
| `json_schema` | Validate JSON | Optional; requires `jsonschema` package |
| `latex` | LaTeX compilation | Optional; requires `pdflatex` |
| `length` | Output size bounds | Built-in; enforces 10‚Äì50,000 characters |

#### Multi-Round Critique & Revision

Each task executes a generate ‚Üí critique ‚Üí revise loop:
1. **GENERATE** ‚Äî Primary model produces output
2. **CRITIQUE** ‚Äî Different provider provides feedback
3. **REVISE** ‚Äî Primary model improves based on critique
4. **EVALUATE** ‚Äî 2√ó independent LLM scoring with self-consistency check (Œî ‚â§ 0.05)

**Iteration Limits:**
- Code generation: 3 iterations
- Code review: 4 iterations (extra pass for context quality)
- Reasoning: 3 iterations
- Other tasks: 2 iterations

---

### 4. Policy Governance & Compliance

#### Policy-as-Code Framework

First-class `Policy` objects enable declarative compliance rules:

- **HARD mode** ‚Äî Block any violation; raise exception
- **SOFT mode** ‚Äî Log violation; allow execution
- **MONITOR mode** ‚Äî Log only; never block

**Supported Constraints:**
- Allowed/blocked providers by region
- Training prohibition (`allow_training_on_output`)
- Cost caps per task
- Latency SLAs
- Quality thresholds
- Rate limits

#### Hierarchical Policy Enforcement

Policy inheritance from highest to lowest priority:

```
Org-level (global defaults)
  ‚Üì
Team-level (override org)
  ‚Üì
Job-level (override team)
  ‚Üì
Node-level (specific task)
```

#### Policy DSL (YAML/JSON)

Externalize policies in declarative files:

```yaml
global:
  - name: gdpr
    allow_training_on_output: false
    enforcement_mode: hard

team:
  eng:
    - name: eu_only
      allowed_regions: [eu, global]
      cost_cap_usd: 0.50
```

**Static Analysis:** `PolicyAnalyzer` detects contradictions before execution.

---

### 5. Advanced Observability & Telemetry

#### OpenTelemetry Tracing

Full distributed tracing support with:
- Span instrumentation per task
- Trace context propagation
- OTLP exporter support

**Traced Operations:**
- `run_project` ‚Äî Root span covering entire execution
- Task generation, critique, revision
- Policy checks and validations
- Model API calls

#### Telemetry Metrics Collection

Real-time telemetry tracking across all models:

**Metrics Per Model:**
- `calls_total` ‚Äî Total API calls
- `success_rate` ‚Äî Percentage of successful calls
- `latency_avg_ms` ‚Äî EMA-smoothed average latency
- `latency_p95_ms` ‚Äî Real p95 from sorted 50-sample buffer (not 2√óavg approximation)
- `quality_score` ‚Äî EMA-tracked quality metric
- `trust_factor` ‚Äî Dynamic trust level (0‚Äì1, adjusts on success/failure)
- `cost_avg_usd` ‚Äî EMA-tracked per-call cost
- `validator_failures_total` ‚Äî Count of hard validator failures

**Real p95 Calculation:** Maintains sorted circular buffer of last 50 samples; computes true 95th percentile (not formula-based).

---

## Advanced Capabilities

### 6. Architecture Advisor ‚Äî LLM-Powered Architecture Decisions

**New in 2026-02:** Before generating any code, `ArchitectureAdvisor` makes intelligent architectural decisions:

**Input:** Project description + success criteria
**Output:** `ArchitectureDecision` specifying:
- **structural_pattern** (layered, hexagonal, CQRS, event-driven, MVC, script)
- **topology** (monolith, microservices, serverless, BFF, library)
- **api_paradigm** (REST, GraphQL, gRPC, CLI, none)
- **data_paradigm** (relational, document, time-series, key-value, none)
- **rationale** (2‚Äì3 sentences explaining the choices)

**Model Selection:**
- Descriptions >50 words ‚Üí DeepSeek Reasoner (multi-dimensional reasoning)
- Descriptions ‚â§50 words ‚Üí DeepSeek Chat (fast, cost-effective)
- Fallback: Kimi K2.5 ‚Üí Claude Opus ‚Üí GPT-4o

**Benefits:**
- Ensures all generated tasks follow a **consistent, coherent architecture**
- Reduces rework and architectural drift
- Injects constraints into decomposition prompt
- Automatic terminal summary (`üèó Architecture Decision`)
- Full backward compatibility with `AppDetector`

**Usage:**
```python
advisor = ArchitectureAdvisor()
decision = await advisor.analyze(
    description="Build a FastAPI microservice",
    criteria="High throughput, auto-scaling"
)
print(decision.structural_pattern)  # "hexagonal" or chosen pattern
print(decision.topology)            # "microservices"
```

---

### 7. Multi-Objective Optimization Backends

Three pluggable routing strategies:

- **GreedyBackend** ‚Äî Single-winner: maximize `quality √ó trust / cost`
- **WeightedSumBackend** ‚Äî Tunable: `w_quality`, `w_trust`, `w_cost` weights
- **ParetoBackend** ‚Äî Principled: non-dominated Pareto-optimal solutions

### 8. Economic Layer & Cost Prediction

- **AdaptiveCostPredictor:** EMA-tracked per-(model √ó task) costs
- **BudgetHierarchy:** Cross-run org/team/job spending caps
- **CostForecaster:** Pre-flight estimation with risk assessment

### 9. Multi-Agent Ensembles

- **AgentPool:** Run N orchestrators in parallel (A/B testing, ensemble voting)
- **TaskChannel:** Pub-sub messaging between tasks with non-destructive peek

### 10. Audit & Compliance

- **AuditLog:** Immutable JSONL structured audit trail
- **PolicyAnalyzer:** Static policy contradiction detection

### 11. App Builder & Scaffolding (with Architecture Advisor)

- **AppBuilder:** Auto-generate complete web/backend applications
- **ArchitectureAdvisor:** LLM-powered architectural decision making (NEW)
- **AppDetector/AppProfile:** Legacy support for backward compatibility
- **Supported types:** Next.js, React+Vite, HTML, FastAPI, GraphQL, microservices

### 12. Constraint Control Plane

- **JobSpecV2/PolicySpecV2:** Structured specs for hard constraint enforcement
- **ReferenceMonitor:** Synchronous, bypass-proof constraint checker
- **OrchestrationAgent:** Natural language intent ‚Üí structured specs

### 13. Semantic Caching & Deduplication

- **SemanticCache:** Cache based on semantic similarity (not just hash)
- **DuplicationDetector:** Merge near-duplicate tasks automatically

### 14. Adaptive Routing

- **AdaptiveRouter:** Dynamically adjust model selection based on observed performance
- **ModelState:** Per-model telemetry tracking (latency, quality, trust)

### 15. Remediation Engine

- **RemediationEngine:** Auto-recovery strategies on task failure
- **RemediationPlan:** Retry same/fallback model, loosen constraints, escalate, or abort

### 16. Real-Time Progress & Visualization

- **ProgressRenderer:** Live terminal tree view of task progress
- **DagRenderer:** Directed acyclic graph visualization with costs
- **ProjectEventBus:** Async event streaming for monitoring

---

## Environment Variables

```bash
# At least one provider key required
export OPENAI_API_KEY="sk-..."
export GOOGLE_API_KEY="AIzaSy..."
export ANTHROPIC_API_KEY="sk-ant-..."
export KIMI_API_KEY="sk-..."
export DEEPSEEK_API_KEY="sk-..."

# Optional tracing
export OTEL_EXPORTER_OTLP_ENDPOINT="http://localhost:4318"

# Optional
export ORCHESTRATOR_CACHE_DIR="~/.orchestrator_cache"
export ORCHESTRATOR_LOG_LEVEL="INFO"
```

---

## Quick Feature Checklist

| Feature | Status | Notes |
|---------|--------|-------|
| Multi-provider routing | ‚úÖ | 5 providers, 7+ models each |
| Cost optimization | ‚úÖ | EMA-tracked, adaptive |
| Deterministic validation | ‚úÖ | 6 validator types |
| Cross-provider critique | ‚úÖ | Different provider each review |
| Policy governance | ‚úÖ | HARD/SOFT/MONITOR modes |
| OTEL tracing | ‚úÖ | Full distributed tracing |
| Telemetry & metrics | ‚úÖ | Real p95, trust factor EMA |
| Multi-objective optimization | ‚úÖ | Greedy, Weighted, Pareto |
| Pre-flight cost forecasting | ‚úÖ | Risk assessment |
| **Architecture Advisor** | ‚úÖ | **NEW: LLM architecture decisions** |
| Ensemble/AgentPool | ‚úÖ | Parallel orchestrators |
| Semantic caching | ‚úÖ | Similarity-based dedup |
| App builder | ‚úÖ | With ArchitectureAdvisor |
| Constraint control plane | ‚úÖ | Hard guarantee enforcement |
| Orchestration agent | ‚úÖ | Natural language ‚Üí specs |
| Remediation engine | ‚úÖ | Auto-recovery strategies |
| Real-time visualization | ‚úÖ | Terminal + DAG rendering |
